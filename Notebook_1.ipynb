{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from timeit import default_timer as timer\n",
    "from helper_functions import plot_pie_chart, preprocess_text\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR= 'kaggle/input/emotion-dataset-for-nlp/'\n",
    "TRAIN_FILE = 'train.txt'\n",
    "VAL_FILE = 'val.txt'\n",
    "TEST_FILE = 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DIR+TRAIN_FILE, delimiter=';', header=None, names=['text', 'label'])\n",
    "val_df = pd.read_csv(DIR+VAL_FILE, delimiter=';', header=None, names=['text', 'label'])\n",
    "test_df = pd.read_csv(DIR+TEST_FILE, delimiter=';', header=None, names=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie_chart(train_df, 'Train Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie_chart(val_df, 'Validation Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile helper_functions.py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import spacy\n",
    "\n",
    "with open('SentimentAnalysis/class_names.txt', 'r') as f:\n",
    "    labels = [emotion.strip() for emotion in f.readlines()] \n",
    "    \n",
    "encoder= LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def plot_pie_chart(data_frame: pd.DataFrame, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot a pie chart to visualize label distribution in the provided DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data_frame (pd.DataFrame): The DataFrame containing the data to visualize.\n",
    "        title (str): The title for the pie chart.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    label_count = data_frame['label'].value_counts()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.pie(label_count, labels=label_count.index, colors=sns.color_palette(\"hls\", len(label_count.index)), autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(f\"{title} Label Distribution\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def preprocess_text(df: pd.DataFrame, emotions: list=['love', 'surprise']):\n",
    "    \"\"\"\n",
    "    Preprocesses text data in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'sentence' and 'label' columns.\n",
    "        encoder (LabelEncoder): Label encoder for the labels.\n",
    "        emotions (list): List of emotions to drop from the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with preprocessed text and encoded labels.\n",
    "    \"\"\"\n",
    "    for i in emotions:\n",
    "        df = df[df['label'] != i]\n",
    "\n",
    "    df['processed_text'] = df['text'].apply(lambda x: ' '.join([token.lemma_ for token in nlp(x) if not token.is_stop and not token.is_punct and not token.is_space]))\n",
    "\n",
    "    df['label_num'] = encoder.transform(df['label'])\n",
    "    df.drop(columns=['text', 'label'], inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= preprocess_text(train_df)\n",
    "val_df= preprocess_text(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SentimentAnalysis/class_names.txt', 'r') as f:\n",
    "    labels = [emotion.strip() for emotion in f.readlines()] \n",
    "\n",
    "# Generate and plot word cloud for each label\n",
    "for class_label, text in zip(labels, train_df['processed_text']):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f'Word Cloud for Label: {class_label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE= 15000\n",
    "text_vect_layer= tf.keras.layers.TextVectorization(max_tokens= VOCAB_SIZE)\n",
    "text_vect_layer.adapt(train_df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_UNITS= 64\n",
    "UNITS= 64\n",
    "DROPOUT= 0.2\n",
    "\n",
    "model_v1= tf.keras.Sequential([\n",
    "    text_vect_layer,\n",
    "    layers.Embedding(input_dim=text_vect_layer.vocabulary_size(), output_dim= EMBEDDING_UNITS, mask_zero= True),\n",
    "    layers.GRU(UNITS, dropout= DROPOUT, return_sequences= True),\n",
    "    layers.GRU(UNITS, dropout= DROPOUT),\n",
    "    layers.Dense(len(labels), activation= 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1.compile(optimizer= tf.keras.optimizers.Adam(),\n",
    "                 loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE= 32  \n",
    "train_set= tf.data.Dataset.from_tensor_slices((train_df['processed_text'].values, train_df['label_num'].values)).batch(BATCH_SIZE)\n",
    "val_set= tf.data.Dataset.from_tensor_slices((val_df['processed_text'].values, val_df['label_num'].values)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model_v1.fit(train_set, validation_data= val_set, epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval= model_v1.evaluate(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= 'SentimentAnalysis/models/gru_model.keras'\n",
    "model_v1.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model= tf.keras.models.load_model(f'{file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for a single sentence\n",
    "To make predictions on a single sentence, we need to do the following steps:\n",
    "1. Process it in the same manner to remove the extra token words such (as punctuations)\n",
    "2. Expand the dimension.\n",
    "3. Pass through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SentimentAnalysis/class_names.txt', 'r') as f:\n",
    "    labels = [emotion.strip() for emotion in f.readlines()] \n",
    "\n",
    "with open('SentimentAnalysis/examples.txt', 'r') as f:\n",
    "    example_list = [example.strip() for example in f.readlines()]\n",
    "\n",
    "encoder= LabelEncoder()\n",
    "encoder.fit(labels) \n",
    "\n",
    "model = tf.keras.models.load_model('SentimentAnalysis/models/gru_model.keras')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def preprocess_single_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Preprocesses a single sentence.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): Input sentence.\n",
    "\n",
    "    Returns:\n",
    "        str: Preprocessed and tokenized sentence.\n",
    "    \"\"\"\n",
    "    processed_text = ' '.join([token.lemma_ for token in nlp(sentence) if not token.is_stop and not token.is_punct and not token.is_space])\n",
    "    return processed_text\n",
    "\n",
    "def predict(text):\n",
    "    \"\"\"\n",
    "    Make predictions on the given text using the trained model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to make predictions on.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of predictions.\n",
    "    \"\"\"\n",
    "    start_time= timer()\n",
    "    text= preprocess_single_sentence(text)\n",
    "    text= tf.expand_dims(text, 0)\n",
    "\n",
    "    probability = model.predict(text)\n",
    "    pred_label_with_prob= {labels[i]: float(probability[0][i]) for i in range(len(labels))} \n",
    "    pred_time = round(timer() - start_time, 5)\n",
    "    return pred_label_with_prob, pred_time\n",
    "\n",
    "### Gradio App\n",
    "input= gr.Textbox(lines=5, label=\"Enter text\", placeholder=\"i like to have the same breathless feeling as a reader eager to see what will happen next\")\n",
    "outputs=[\n",
    "        gr.Label(num_top_classes=len(labels), label=\"Predictions\"),\n",
    "        gr.Number(label=\"Prediction time (s)\"),\n",
    "    ]\n",
    "title= ' Sentiment Analysis 🤣😱😡😢 '\n",
    "description= 'The sentiment analysis model is a deep learning-based natural language processing (NLP) model designed to analyze and classify the sentiment expressed in text data. It is trained to understand the emotional tone of text and categorize it into predefined sentiment categories such as <b>anger, fear, saddness and joy.<b>'\n",
    "demo= gr.Interface(fn=predict, \n",
    "                   inputs=input, \n",
    "                   outputs=outputs, \n",
    "                   title=title, \n",
    "                   description=description,\n",
    "                   examples= example_list\n",
    "                  )\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
